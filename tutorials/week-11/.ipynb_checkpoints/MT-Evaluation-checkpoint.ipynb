{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d4f6d2-dc8a-40cc-8450-37e1cdefea06",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67a172ab-5c82-4f8d-abd6-d007603353e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -quiet transformers datasets evaluate\n",
    "!pip install unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d523c-150d-4c20-8941-4c660b0816d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377b8a31-981e-453f-9e2f-5c8dd746ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0fe7ac-8c7d-42ef-b884-2298f1def172",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af6d61-1149-4919-86a3-6948fd1cda16",
   "metadata": {},
   "source": [
    "### 2. Zero-shot Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a32b6b8-161f-4637-b1ce-f4a13696e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data prep\n",
    "df = pd.read_csv(\"./data/short_test_eng_fre.tsv\", sep=\"\\t\")\n",
    "# convert the data into hf dataset format\n",
    "dataset = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d6c1ec-365f-47d9-a152-fe32b7f648f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['English', 'French'],\n",
      "    num_rows: 85\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3ccac-34da-4ada-a075-b54457decc85",
   "metadata": {},
   "source": [
    "#### 2.1 Supervised Translation Model - NLLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab24427b-46a0-46f5-85a3-3661de6ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\" # Read more about the model here: https://huggingface.co/facebook/nllb-200-distilled-600M\n",
    "\n",
    "# model specific parameters\n",
    "task=\"translation\"\n",
    "src_lang = \"eng_Latn\"\n",
    "tgt_lang = \"fra_Latn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aafff5aa-4eae-450f-8791-66903b1b4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = transformers.pipeline(task, model=model_name, src_lang=src_lang, tgt_lang=tgt_lang, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08a7fdd3-cae4-4543-b782-17ddd75985dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "#  Inputs are passed to the model in batch. \n",
    "for output in translator(KeyDataset(dataset, \"English\"), batch_size=4, truncation=\"only_first\"):\n",
    "\n",
    "    # append the output into outputs\n",
    "    outputs.append(output[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09db80e4-c08e-4561-ac88-7fc73cdc9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions into df and store \n",
    "df[model_name.split(\"/\")[-1]] = outputs\n",
    "df.to_csv(f\"data/{model_name.split('/')[-1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e98539-0fcd-43e0-8876-9eedd6597046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "570e8c35-7c41-4bf2-805d-604b526eb110",
   "metadata": {},
   "source": [
    "#### 2.2 Translation with Instruction Following Models - Excercise\n",
    "\n",
    "1. Do the translation with any instruction following the model (ideally of comparable size). \n",
    "2. Run the evaluation.\n",
    "3. Report your results and compare them against that of NLLB baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881549b0-af97-41fb-9f4f-01cecb9e6a51",
   "metadata": {},
   "source": [
    "### 3. Supervised Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918e4306-3097-42d9-97c2-8d0e087dd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe with predictions\n",
    "df = pd.read_csv(\"data/nllb-200-distilled-600M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb708e4e-7ba3-4f5b-bff7-bb5b57915868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>nllb-200-distilled-600M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A guy works on a building.</td>\n",
       "      <td>Un gars travaille sur un bâtiment.</td>\n",
       "      <td>Un type travaille sur un bâtiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people sit in a cave.</td>\n",
       "      <td>Trois personnes sont assises dans une grotte.</td>\n",
       "      <td>Trois personnes sont dans une cave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People standing outside of a building.</td>\n",
       "      <td>Des gens debout devant un bâtiment.</td>\n",
       "      <td>Des gens debout à l'extérieur d'un bâtiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man cutting branches of trees.</td>\n",
       "      <td>Un homme coupant les branches d'un arbre.</td>\n",
       "      <td>Un homme coupe des branches d'arbres.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A child is splashing in the water</td>\n",
       "      <td>Un enfant éclabousse dans l'eau</td>\n",
       "      <td>Un enfant est en train de sauter dans l'eau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English  \\\n",
       "0              A guy works on a building.   \n",
       "1             Three people sit in a cave.   \n",
       "2  People standing outside of a building.   \n",
       "3        A man cutting branches of trees.   \n",
       "4       A child is splashing in the water   \n",
       "\n",
       "                                          French  \\\n",
       "0             Un gars travaille sur un bâtiment.   \n",
       "1  Trois personnes sont assises dans une grotte.   \n",
       "2            Des gens debout devant un bâtiment.   \n",
       "3      Un homme coupant les branches d'un arbre.   \n",
       "4                Un enfant éclabousse dans l'eau   \n",
       "\n",
       "                        nllb-200-distilled-600M  \n",
       "0            Un type travaille sur un bâtiment.  \n",
       "1           Trois personnes sont dans une cave.  \n",
       "2  Des gens debout à l'extérieur d'un bâtiment.  \n",
       "3         Un homme coupe des branches d'arbres.  \n",
       "4   Un enfant est en train de sauter dans l'eau  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd0712-e208-4297-829f-4f6b16dbfa91",
   "metadata": {},
   "source": [
    "#### 3.1 BLEU Score\n",
    "1. Bilingual Evaluation Understudy.\n",
    "2. Quality is considered to be the correspondence between a machine’s output and that of a human: “the closer a machine translation is to a professional human translation, the better it is”.\n",
    "3. The BLEU score is computed as follows:\n",
    "\n",
    "![Alt text](data/assets/bleu.png)\n",
    "\n",
    "4. In summary, the BLEU score combines precision scores for different n-gram sizes and applies a brevity penalty to compute a final score that represents the quality of the machine-translated text relative to the reference translations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3a72f-8be3-4f38-a350-7632db8ccff6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564df8bc-9c0e-4550-95d7-0d92496a2d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "013f859f-2406-4929-afc5-7e0a9bcf8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.94k/5.94k [00:00<00:00, 11.0MB/s]\n",
      "Downloading extra modules: 4.07kB [00:00, 4.41MB/s]                                                                                                                                                                \n",
      "Downloading extra modules: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.34k/3.34k [00:00<00:00, 8.10MB/s]\n"
     ]
    }
   ],
   "source": [
    "# load the metrics from hf evaluate package\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e76ff0f-e093-4539-a5c8-2d1177be2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_results = bleu.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'], max_order=4) \n",
    "# max_order: Maximum n-gram order to use when computing BLEU score. Defaults to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "867fd07f-7d52-4bab-b938-e086356c5e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4065892614949111,\n",
       " 'precisions': [0.6751412429378532,\n",
       "  0.47191011235955055,\n",
       "  0.34386617100371747,\n",
       "  0.24944812362030905],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0260869565217392,\n",
       " 'translation_length': 708,\n",
       " 'reference_length': 690}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30e4a-a821-4741-a390-716cd60c5de3",
   "metadata": {},
   "source": [
    "#### 3.2 METEOR\n",
    "1. Metric for Evaluation of Translation with Explicit Ordering\n",
    "2. METEOR can be formulated as:\n",
    "3. ![Alt text](data/assets/meteor.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "453fc8f6-84f8-4771-b172-4e8a586f8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.93k/6.93k [00:00<00:00, 11.4MB/s]\n",
      "[nltk_data] Downloading package wordnet to /home/abdul/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "meteor = evaluate.load('meteor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3982d425-3642-4013-b743-d4e2e754dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_results = meteor.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19d4e7c0-67f7-4373-b50b-d845bfa95ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor': 0.6448424005309302}\n"
     ]
    }
   ],
   "source": [
    "print(meteor_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7763b7-48f1-4805-8e92-be4d611de5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65834f26-2c95-40dd-b490-fe58a26f2e08",
   "metadata": {},
   "source": [
    "#### 3.2 ChrF and ChrF++\n",
    "1. Character n-gram F-score.\n",
    "2. ChrF and ChrF++ are two MT evaluation metrics that use the F-score statistic for character n-gram matches. ChrF++ additionally includes word n-grams, which correlate more strongly with direct assessment.\n",
    "3. ChrF++ is ChrF with a word order of 2 (or 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9125ea68-5273-4cd8-aa91-4460306136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a52a3b82-17dd-4a78-afd8-51c85281688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf_results = chrf.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7274be1-57db-4cd5-952c-32bd19f0fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 64.03435195758375, 'char_order': 6, 'word_order': 0, 'beta': 2}\n"
     ]
    }
   ],
   "source": [
    "print(chrf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07947b63-db0c-4866-91f3-045190de9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrfp_results = chrf.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'], word_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d68a6b-fcf5-4100-8fd5-d605e65da8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 62.683079599172984, 'char_order': 6, 'word_order': 2, 'beta': 2}\n"
     ]
    }
   ],
   "source": [
    "print(chrfp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424e042-184a-4839-942c-dbc7cc19cd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "847a7809-cd62-4f3b-bc7c-78b27d71e741",
   "metadata": {},
   "source": [
    "#### 3.3 TER \n",
    "1. Translation Edit Rate\n",
    "2. TER Score is computed as:\n",
    " \n",
    "  ![Alt text](data/assets/ter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14028c17-89e2-41cf-b208-818f37b83df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.99k/9.99k [00:00<00:00, 15.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "ter = evaluate.load(\"ter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e01eacc-6f92-44b5-a033-e82b95f1c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_results = ter.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f38198d6-c346-48cb-a7c5-f490fd45623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 43.08943089430895, 'num_edits': 265, 'ref_length': 615.0}\n"
     ]
    }
   ],
   "source": [
    "print(ter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15305f0d-7d7a-490d-856b-2db2d6e41652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a9ff3-a4cd-456c-993b-b46c8a36294b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d83ab8-e565-470c-8370-b50900cb6f45",
   "metadata": {},
   "source": [
    "#### 3.4 COMET\n",
    "1. COMET - Cross-lingual Optimal MEtadata-based Translation\n",
    "2. A score close to 1 indicates a high-quality translation, while a score close to 0 indicates a translation that is no better than random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8abaa01-7f54-412f-aa9e-7974ecc4407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 30481.86it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.2.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/371e9839ca4e213dde891b066cf3080f75ec7e72/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/abdul/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "comet = evaluate.load('comet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39bdf42-3cae-480c-a965-b34254972b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "comet_score = comet.compute(predictions=df['nllb-200-distilled-600M'], references=df['French'], sources=df['English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d1f334-2382-451f-a00d-0ca19f80d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841721477578668\n"
     ]
    }
   ],
   "source": [
    "print(comet_score['mean_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a727ef2-67d1-4a0e-a1df-33aa63a7cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6436a4be-fdae-4609-bdd9-50accc54d08d",
   "metadata": {},
   "source": [
    "### 4. Unsupervised Evaluations\n",
    "- Also known as reference-free evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adb50e-55f9-491d-833d-e9b66fe848f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a0f182-13f9-4079-93fe-718cfbf73d24",
   "metadata": {},
   "source": [
    "#### 4.1 Human Evaluation\n",
    "1. Prepare set of guidelines for rating critieria.\n",
    "2. Provide pair of source and target language sentences and ask humans to evaluate the translation based on rating criteria.\n",
    "3. Do 2 for multiple sentences and human evaluators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede33d8-6e1d-40c5-a980-3d35549e5ca6",
   "metadata": {},
   "source": [
    "#### 4.2 LLM Judge\n",
    "- Using powerful multilingual large language models such as ChatGPT, Gemni, and Claude as judges to assess the quality of translation. \n",
    "- Correlates with human evaluation. \n",
    "- Prone to score high/better to outputs produced by itself.\n",
    "- Not uniformly good for all languages.\n",
    "- Doing 4.1 but with LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15bea9d9-c6ac-4d76-ab9d-9495ea0b3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331993d9-5276-4902-88a5-5f0d2a819c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e44d8c9f-ece8-4626-b2da-e27050e81d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openchat/openchat-3.5-0106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3072376d-d8e9-4cf7-9133-d02652b64566",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1584e4-5077-422b-a3a5-bb3bcaf58e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = open(\"data/prompts/prompt.txt\", \"r\").read()\n",
    "guideline = open(\"data/prompts/guideline.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8c7972e-0e06-48c4-9042-b7c4f8543866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>nllb-200-distilled-600M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A guy works on a building.</td>\n",
       "      <td>Un gars travaille sur un bâtiment.</td>\n",
       "      <td>Un type travaille sur un bâtiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three people sit in a cave.</td>\n",
       "      <td>Trois personnes sont assises dans une grotte.</td>\n",
       "      <td>Trois personnes sont dans une cave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People standing outside of a building.</td>\n",
       "      <td>Des gens debout devant un bâtiment.</td>\n",
       "      <td>Des gens debout à l'extérieur d'un bâtiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man cutting branches of trees.</td>\n",
       "      <td>Un homme coupant les branches d'un arbre.</td>\n",
       "      <td>Un homme coupe des branches d'arbres.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A child is splashing in the water</td>\n",
       "      <td>Un enfant éclabousse dans l'eau</td>\n",
       "      <td>Un enfant est en train de sauter dans l'eau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English  \\\n",
       "0              A guy works on a building.   \n",
       "1             Three people sit in a cave.   \n",
       "2  People standing outside of a building.   \n",
       "3        A man cutting branches of trees.   \n",
       "4       A child is splashing in the water   \n",
       "\n",
       "                                          French  \\\n",
       "0             Un gars travaille sur un bâtiment.   \n",
       "1  Trois personnes sont assises dans une grotte.   \n",
       "2            Des gens debout devant un bâtiment.   \n",
       "3      Un homme coupant les branches d'un arbre.   \n",
       "4                Un enfant éclabousse dans l'eau   \n",
       "\n",
       "                        nllb-200-distilled-600M  \n",
       "0            Un type travaille sur un bâtiment.  \n",
       "1           Trois personnes sont dans une cave.  \n",
       "2  Des gens debout à l'extérieur d'un bâtiment.  \n",
       "3         Un homme coupe des branches d'arbres.  \n",
       "4   Un enfant est en train de sauter dans l'eau  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e36e914-d67c-4925-b157-ef1c97b24cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(src_lang=\"English\", tgt_lang=\"French\", guideline=guideline, source=df['English'].iloc[0], target=df['nllb-200-distilled-600M'].iloc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9afa2baa-acfc-4b10-9eba-8e31d5932f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evaluate the provided translation from English to French according to the following criteria:\\n\\nGuideline:\\nCompleteness:\\n1. Includes all essential information from the source text without omission.\\n2. Captures main ideas, key details, and nuances accurately.\\n\\nAccuracy:\\n1. Reflects the meaning and intent of the source text faithfully without distortion.\\n2. Translates vocabulary, idiomatic expressions, and technical terms accurately.\\n\\nConsistency:\\n1. Maintains terminology, style, and tone consistency throughout the translation.\\n2. Ensures coherence and clarity across sentences and paragraphs.\\n\\nFormat Compliance:\\n1. Adheres to the required format or structure specified for the target text, if applicable.\\n2. Follows any formatting guidelines provided, such as headings, bullet points, or paragraphs.\\n\\nOriginality:\\n1. Demonstrates originality and independent generation.\\n2. Avoids verbatim repetition of source text and introduces variation in language usage.\\n\\nRatings:\\n1: The translation significantly lacks completeness, accuracy, consistency, format compliance, and originality.\\n2: The translation is deficient in several aspects, with notable deficiencies in completeness, accuracy, consistency, format compliance, or originality.\\n3: The translation is average, with some shortcomings in completeness, accuracy, consistency, format compliance, or originality.\\n4: The translation is good, with minor issues in completeness, accuracy, consistency, format compliance, or originality.\\n5: The translation is exceptional, meeting all criteria with no issues whatsoever.\\n\\nEnglish: A guy works on a building.\\nFrench: Un type travaille sur un bâtiment.\\n\\nPlease assign a rating from 1 to 5 based on how well the translation adheres to the provided guidelines. Provide only a rating nothing else.\\n\\nRating: []\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064bd38-48c6-465f-9ed0-ec012023f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f147aab9-b999-4597-a3bd-4c4fba5aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = chatbot(\n",
    "    prompt,\n",
    "    do_sample=False,\n",
    "    return_full_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c016052-fab4-4f5c-9f66-5e19458980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b92b8-87c3-4521-b472-02947eaece59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a66b14-6c89-4b11-98d0-662f0b757cee",
   "metadata": {},
   "source": [
    "#### 4.3 UScore, XMoverScore, SentSim\n",
    "1. https://github.com/potamides/unsupervised-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756a6ed-193e-4d11-9482-662242b1535f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bad4e57-275f-4031-b976-c7f4c1706b72",
   "metadata": {},
   "source": [
    "### 5. References (Recommended Reading)\n",
    "  1. https://aclanthology.org/2023.eacl-main.27.pdf\n",
    "  2. https://aclanthology.org/2023.acl-short.55/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73be10c-a36e-4411-b362-419f3c5ca0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
